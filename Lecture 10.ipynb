{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9e812b91-4172-42ad-9ee9-ca059e27c97a",
   "metadata": {},
   "source": [
    "## Higher-order Approximations\n",
    "\n",
    "Although forward/backward and especially central difference methods are amply sufficient to compute derivatives, in certain cases, it is useful to employ higher order approximations. Fitting a polynomial of higher degree to a function $f(x)$ can result in better approximations of $dy/dx$.  \n",
    "If you fit a quadratic to $f(x)$, you actually get central difference.  \n",
    "Similarly, you can fit a cubic, quintic, etc. (odd-degrees) or quadratic, quartic, etc. (even-degrees), to get better approximations.  \n",
    "Generally, odd-degree approximations are slightly better.\n",
    "\n",
    "## Second-drivatives\n",
    "\n",
    "$$ f^{\\prime\\prime}(x) \\simeq \\frac{f(x+h)-2f(x)+f(x-h)}{h^2} $$\n",
    "\n",
    "$$ \\epsilon = \\frac{4C|f(x)|}{h^2} + \\frac{1}{12}h^2f^{\\prime\\prime\\prime\\prime}(x) $$\n",
    "\n",
    "## Partial Derivatives\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\frac{\\partial f(x,y)}{\\partial x} =& \\frac{f(x+h/2,y)-f(x-h/2,y)}{h} \\\\\n",
    "\\frac{\\partial f(x,y)}{\\partial y} =& \\frac{f(x,y+h/2)-f(x,y-h/2)}{h} \n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "$$ \n",
    "\\frac{\\partial^2 f(x,y)}{\\partial x\\partial y} = \\frac{f(x+h/2,y+h/2)-f(x-h/2,y+h/2)-f(x+h/2,y-h/2)+f(x-h/2,y-h/2)}{h^2}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf5d0e9b-a4d2-4ba2-b058-a2cc55004d55",
   "metadata": {},
   "source": [
    "## Noisy Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eea56f2-6cba-4059-be6d-3370420f06ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "t = np.linspace(0, 100, 1000)\n",
    "x = 10*np.sin(t/(2*np.pi))\n",
    "# generating noise\n",
    "noise = np.random.normal(0,2, len(x)) #  Gaussian noise: μ = 0, σ = 2, size = length of data.\n",
    "\n",
    "# Add the noise to the data. \n",
    "x_noised = x + noise\n",
    "\n",
    "# plotting noisy data\n",
    "plt.plot(t,x_noised)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40ecc052-6f65-44a6-b7c0-e194665c301b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# simple function to calculate derivative using forward difference\n",
    "def cdiff(x,t):\n",
    "    dx = x[1:]-x[:-1]\n",
    "    dt = t[1:]-t[:-1]\n",
    "    return dx/dt\n",
    "\n",
    "#plotting derivative\n",
    "plt.plot(t[1:],cdiff(x_noised,t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c111ba71-6372-4410-9097-1ca3ace3054a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# zoomed-in noisy data\n",
    "plt.plot(t,x_noised)\n",
    "plt.xlim(0,20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bea13342",
   "metadata": {},
   "outputs": [],
   "source": [
    "# zoomed-in derivative\n",
    "plt.plot(t[1:],cdiff(x_noised,t))\n",
    "plt.xlim(0,20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fec365c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# decreasing h\n",
    "h = 1e-12\n",
    "deriv = np.gradient(x_noised,h)\n",
    "plt.plot(t,deriv)\n",
    "plt.xlim(0,20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ae8b292",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fitting a smoother function is a solution\n",
    "# OR Apply smoothing function to the noisy data\n",
    "\n",
    "from scipy.signal import savgol_filter    # Savitzky-Golay filter\n",
    "\n",
    "x_noise_removed = savgol_filter(x_noised, 15, 3)\n",
    "plt.plot(t, x_noise_removed)  # 15 is number of coefficients in the fitted polynomial (less than signal array size), 3 is the order of polynomial used to fit the sample\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84df3874",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculating and plotting derivative of smoothed data\n",
    "h = 1e-2\n",
    "deriv = np.gradient(x_noise_removed,h)\n",
    "plt.plot(t,deriv)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f9ad2a2",
   "metadata": {},
   "source": [
    "# Interpolation\n",
    "\n",
    "Let us say we have a function $f(x)$ with known values at $x=a$ and $x=b$. If we want to find a value at some point $a<x<b$, we have to use the method of interpolation.  \n",
    "The simplest method is linear interpolation.  \n",
    "$$ f(x) \\simeq y+z = \\frac{(b-x)f(a)+(x-a)f(b)}{b-a} $$\n",
    "Higher-order polynomial fitting (Lagrange polynomial) obviously provides better approximations, although for very large N, wiggles due to boundaries may arise (Runges's phenomenon).  \n",
    "\n",
    "### Best approach -- Splines\n",
    "**Cubic splines** is a method that combines piecewise fitting of a cubic and subsequent matching of derivatives at their ends to produce a smooth slope."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
